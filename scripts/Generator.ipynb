{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import torch\n",
    "import numba\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm \n",
    "from transformers import AutoTokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Needed things\n",
    "cdr3 length \n",
    "- based on the empirical distributions found from train data\n",
    "\n",
    "How to choose genes\n",
    "- same genes as in the test data?\n",
    "- check GRU git generation system\n",
    "\n",
    "Evaluation metrics\n",
    "- GRU paper and git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CDR3 length distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(), os.pardir, \"data\")\n",
    "emerson_path =os.path.join(data_path, \"emerson\", \"emerson_processed\")\n",
    "test_data = pd.read_csv(os.path.join(emerson_path, \"whole_seqs_nn_test.tsv\"), sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(forceobj=True)\n",
    "def gene_combination_cdr3(data):\n",
    "    result = {}\n",
    "    for i in tqdm(range(data.shape[0]), position = 0, leave = True):\n",
    "        v = f'{data[i, 3]}*{int(data[i, 4])}'\n",
    "        j = f'{data[i, 6]}*{int(data[i, 7])}'\n",
    "        cdr3_len = len(data[i,1])\n",
    "        if (v, j) not in result.keys():\n",
    "            result[(v,j)] = [cdr3_len]\n",
    "        else:\n",
    "            result[(v,j)].append(cdr3_len)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26427243/26427243 [01:08<00:00, 384997.90it/s]\n"
     ]
    }
   ],
   "source": [
    "gene_cdr3 = gene_combination_cdr3(test_data.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 359/359 [00:09<00:00, 38.13it/s] \n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(gene_cdr3.keys(), total = len(gene_cdr3), position = 0, leave = True):\n",
    "    cdr3_count = {}\n",
    "    total = 0\n",
    "    lengths = gene_cdr3[i]\n",
    "    lengths.sort()\n",
    "    for j in lengths:\n",
    "        key = j\n",
    "        if key not in cdr3_count.keys():\n",
    "            cdr3_count[key] = 1\n",
    "        else:\n",
    "            cdr3_count[key] += 1\n",
    "        total += 1\n",
    "    cdr3_count.update((x, y/total) for x, y in cdr3_count.items())\n",
    "    gene_cdr3[i] = cdr3_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_length(V, J, distribution):\n",
    "    genes = (V, J)\n",
    "    weights = torch.tensor(list(distribution[genes].values()))\n",
    "    lengths = torch.tensor(list(distribution[genes].keys()))\n",
    "    return int(lengths[int(torch.multinomial(input=weights, num_samples=1,replacement=True))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_length('TRBV7-8*1', 'TRBJ2-3*1', gene_cdr3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_data_new import load_allele_datadict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "allele_dict = load_allele_datadict(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in allele_dict.items():\n",
    "    allele_dict[k] = \" \".join(v[0].replace(\"-\", \"\").replace(\".\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(forceobj=True)\n",
    "def fetch_sequences(data, allele_dict):\n",
    "    result = []\n",
    "    pattern = r'F G [A-Z] G'\n",
    "    for i in tqdm(range(data.shape[0]), position = 0, leave = True):\n",
    "        v = f'{data[i, 3]}*0{int(data[i, 4])}'\n",
    "        seq_v = allele_dict[v]\n",
    "        seq_v = seq_v[:seq_v.rfind('C')+1]\n",
    "        \n",
    "        \n",
    "        # The last element of the cdr3 is the F in 'combining region'\n",
    "        # https://www.imgt.org/IMGTrepertoire/Proteins/alleles/index.php?species=Homo%20sapiens&group=TRBJ&gene=TRBJ-overview\n",
    "        \n",
    "        j = f'{data[i, 6]}*0{int(data[i, 7])}'\n",
    "        seq_j = allele_dict[j]\n",
    "        match = re.search(pattern, seq_j)\n",
    "        seq_j = seq_j[match.start()+2:] # F included in cdr3 and space is removed\n",
    "        \n",
    "        result.append([seq_v, seq_j])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 2378.58it/s]\n"
     ]
    }
   ],
   "source": [
    "data = test_data.iloc[0:2000].to_numpy()\n",
    "seqs = fetch_sequences(data, allele_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'G P G T R L T V T'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('Rostlab/prot_bert_bfd', add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_seqs = []\n",
    "for i in range(len(seqs)):\n",
    "    V = tokenizer(seqs[i][0],  return_tensors='pt')['input_ids'][:,:-1] # remove [SEP]\n",
    "    J = tokenizer(seqs[i][1],  return_tensors='pt')['input_ids'][:,1:] # remove [CLS]\n",
    "    tokenized_seqs.append([V, J])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/blog/how-to-generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The V and J genes are given to model \n",
    "- The model utilise cdr3 length distribution to sample the length of the CDR3 sequence\n",
    "    - The key needs to be constructed \n",
    "- V, CDR3 and J need to be concat\n",
    "    - Is there possibility to use batch --> the sequences are not generated one by one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomprotBERT(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30, 1024, padding_idx=0)\n",
       "    (position_embeddings): Embedding(40000, 1024)\n",
       "    (token_type_embeddings): Embedding(2, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-29): 30 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (norm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=30, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint =  torch.load(\"../code/model_2/030823_customprotBERT_parallel_checkpoint.pth\",  map_location=\"cpu\")\n",
    "model = checkpoint[\"model\"]\n",
    "model = model.module\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Greedy search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_search(model, Vs, Js, length):\n",
    "    with torch.no_grad():\n",
    "        prob = []\n",
    "        cdr3_length = int(length[:,1])\n",
    "        cdr3_pred =torch.full((1,cdr3_length), 0)\n",
    "        for i in tqdm(range(cdr3_length), leave=True, position=0):\n",
    "\n",
    "            src = torch.cat((Vs,cdr3_pred,Js), axis=-1)\n",
    "            out = model(src=src,\n",
    "                       length = length)\n",
    "            cdr3_pred[:,i]= out.softmax(-1).argmax(-1)[:,i]\n",
    "            prob.append(out.softmax(-1)[:,i,:])\n",
    "    return cdr3_pred, prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Temperature sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature_sample(model, Vs, Js, length, temperature):\n",
    "    with torch.no_grad():\n",
    "        prob = []\n",
    "        cdr3_length = int(length[:,1])\n",
    "        cdr3_pred =torch.full((1,cdr3_length), 0)\n",
    "        for i in tqdm(range(cdr3_length), leave=True, position=0):\n",
    "\n",
    "            src = torch.cat((Vs,cdr3_pred,Js), axis=-1)\n",
    "            out = model(src=src,\n",
    "                       length = length)\n",
    "\n",
    "            out = out/temperature\n",
    "            probs = out.softmax(-1)\n",
    "            \n",
    "            next_idx = torch.multinomial(probs[:,i], num_samples=1)\n",
    "            cdr3_pred[:,i]= next_idx\n",
    "            prob.append(probs[:,i,:])\n",
    "    return cdr3_pred, prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Top-k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_sample(model, Vs, Js, length, k):\n",
    "    with torch.no_grad():\n",
    "        prob = []\n",
    "        cdr3_length = int(length[:,1])\n",
    "        cdr3_pred =torch.full((1,cdr3_length), 0)\n",
    "        for i in tqdm(range(cdr3_length), leave=True, position=0):\n",
    "\n",
    "            src = torch.cat((Vs,cdr3_pred,Js), axis=-1)\n",
    "            out = model(src=src,\n",
    "                       length = length)\n",
    "            probs = out.softmax(-1)\n",
    "            \n",
    "            top_values, top_indices = torch.topk(probs[:,i], k)\n",
    "            next_idx = torch.multinomial(top_values.squeeze(0), num_samples=1)\n",
    "            cdr3_pred[:,i]= top_indices[:,next_idx]\n",
    "            prob.append(probs[:,i,:])\n",
    "    return cdr3_pred, prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Top-p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_p_sample(model, Vs, Js, length, p):\n",
    "    with torch.no_grad():\n",
    "        prob = []\n",
    "        cdr3_length = int(length[:,1])\n",
    "        cdr3_pred =torch.full((1,cdr3_length), 0)\n",
    "        for i in tqdm(range(cdr3_length), leave=True, position=0):\n",
    "\n",
    "            src = torch.cat((Vs,cdr3_pred,Js), axis=-1)\n",
    "            out = model(src=src,\n",
    "                       length = length)\n",
    "            probs = out.softmax(-1)\n",
    "            \n",
    "            sort_values, sort_indices = torch.sort(probs[:,i], descending=True, stable=True)\n",
    "            cumulative_probs = torch.cumsum(sort_values, dim=-1)\n",
    "\n",
    "            if cumulative_probs[:,0] > p:\n",
    "                selected_indices = sort_indices[:,0]\n",
    "                norm_probs = sort_values[:,0]/cumulative_probs[:,0][-1]\n",
    "            else:\n",
    "                selected_indices = sort_indices[cumulative_probs <= p]\n",
    "                norm_probs = sort_values[cumulative_probs <= p]/cumulative_probs[cumulative_probs <= p][-1]\n",
    "            \n",
    "            next_idx = torch.multinomial(norm_probs, num_samples=1)\n",
    "            cdr3_pred[:,i]= selected_indices[next_idx]\n",
    "            prob.append(probs[:,i,:])\n",
    "    return cdr3_pred, prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinomial_sample(model, Vs, Js, CDRs, pad_mask, length):\n",
    "    with torch.no_grad():\n",
    "        prob = []\n",
    "        cdr3_length = model.CDR3_max_length\n",
    "        \n",
    "        for i in tqdm(range(cdr3_length), leave=True, position=0):\n",
    "            srcs = [torch.cat([v, cdr,j], axis=-1) for v, cdr, j in zip(Vs,Js,CDRs)]\n",
    "            #print(srcs[0].shape)\n",
    "            src = torch.stack(srcs).to(torch.int)\n",
    "            #print(src)\n",
    "            out = model(src=src,\n",
    "                       length = length,\n",
    "                       pad_mask =pad_mask)\n",
    "            #print(torch.multinomial(out.softmax(-1)[:,i], num_samples=1))\n",
    "            for j in range(len(CDRs)):\n",
    "                if i > CDRs[j].shape[-1]-1:\n",
    "                    continue\n",
    "                CDRs[j][i]= torch.multinomial(out.softmax(-1)[j,i], num_samples=1)\n",
    "            #prob.append(out.softmax(-1)[:,i,:])\n",
    "    return CDRs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:23<00:00,  1.67s/it]\n"
     ]
    }
   ],
   "source": [
    "idx = 588\n",
    "input_data = tokenized_seqs[idx]\n",
    "V = input_data[0]\n",
    "J = input_data[1]\n",
    "V_code = f'{data[idx, 3]}*{int(data[idx, 4])}'\n",
    "J_code = f'{data[idx, 6]}*{int(data[idx, 7])}' \n",
    "length = torch.tensor([V.shape[-1],sample_length(V_code, J_code, gene_cdr3)]).unsqueeze(0)\n",
    "\n",
    "#cdr3_pred, prob = greedy_search(model, V, J, length)\n",
    "#cdr3_pred, prob = temperature_sample(model, V, J, length, 0.01)\n",
    "#cdr3_pred, prob = top_k_sample(model, V, J, length, 6)\n",
    "cdr3_pred, prob = top_p_sample(model, V, J, length, 0.90)\n",
    "#cdr3_pred, prob = multinomial_sample(model, V, J, length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset for generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from process_data_new import load_allele_datadict\n",
    "\n",
    "class GeneratorDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, cdr3_length_distribution, tokenizer, CDR3_max_length):\n",
    "        \n",
    "        self.cdr3_length_distribution = cdr3_length_distribution\n",
    "        self.tokenizer = tokenizer\n",
    "        self.CDR3_max_length = CDR3_max_length\n",
    "        self.V, self.J = fetch_sequences(data)\n",
    "        self.V_codes, self.J_codes = fetch_sequence_codes(data)\n",
    "        \n",
    "        if len(self.V) == 1:\n",
    "            self.V_max_length = len(V[0].split()) + 1 #[CLS] token\n",
    "            self.J_max_length = len(J[0].split()) + 2 #[SEP] token and one [PAD]\n",
    "        else:\n",
    "            length = 0\n",
    "            V_length = 0\n",
    "            J_length = 0\n",
    "            for i in range(len(self.V)):\n",
    "                #print(self.V[i])\n",
    "                V_length = max(V_length, len(self.V[i].split()) + 1) #[CLS] token\n",
    "                J_length = max(J_length, len(self.J[i].split()) + 2) #[SEP] token and one [PAD]\n",
    "            \n",
    "            self.V_max_length = V_length \n",
    "            self.J_max_length =  J_length \n",
    "            self.max_length = V_length + J_length + CDR3_max_length \n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.V)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        cdr3_length = self.sample_length(self.V_codes[idx], self.J_codes[idx])\n",
    "        CDR3 = cdr3_length * \"[UNK]\"\n",
    "        seq = self.V[idx] + \" \" + CDR3 + \" \" + self.J[idx]\n",
    "        \n",
    "        tokenized = self.tokenizer(seq, padding= 'max_length', max_length= self.max_length, return_tensors='pt', return_attention_mask=True)\n",
    "        \n",
    "        padded_tokenized_seq = tokenized['input_ids']\n",
    "        pad_mask = ~tokenized['attention_mask'].to(torch.bool)\n",
    "        \n",
    "        \n",
    "        v_len = len(self.V[idx].split()) + 1 # Tokenizer adds [CLS] token at the beginning of the sequence\n",
    "        lengths = torch.tensor([v_len, cdr3_length])\n",
    "        \n",
    "        V = padded_tokenized_seq[:, :v_len]\n",
    "        J = padded_tokenized_seq[:, v_len+cdr3_length:]\n",
    "        CDR3 = torch.zeros((cdr3_length))\n",
    "        \n",
    "        item = {'v': V.squeeze(0),\n",
    "                'j': J.squeeze(0),\n",
    "                'cdr3': CDR3,\n",
    "                'length': lengths,\n",
    "                'pad_mask': pad_mask.squeeze(0)}\n",
    "        \n",
    "        return item\n",
    "    \n",
    "    def sample_length(self,V, J):\n",
    "        genes = (V, J)\n",
    "        weights = torch.tensor(list(self.cdr3_length_distribution[genes].values()))\n",
    "        lengths = torch.tensor(list(self.cdr3_length_distribution[genes].keys()))\n",
    "        return int(lengths[int(torch.multinomial(input=weights, num_samples=1,replacement=True))])\n",
    "    \n",
    "\n",
    "@numba.jit(forceobj=True)\n",
    "def fetch_sequences(data):\n",
    "    allele_dict = load_allele_datadict(data_path) #remember to replace path\n",
    "    for k, v in allele_dict.items():\n",
    "        allele_dict[k] = \" \".join(v[0].replace(\"-\", \"\").replace(\".\",\"\"))\n",
    "        \n",
    "    Vs, Js = [None]*data.shape[0], [None]*data.shape[0]\n",
    "    for i in tqdm(range(data.shape[0]), position = 0, leave = True):\n",
    "        v = f'{data[i, 3]}*0{int(data[i, 4])}'\n",
    "        seq_v = allele_dict[v]\n",
    "        Vs[i] = seq_v[:seq_v.rfind('C')+1]\n",
    "        \n",
    "        # The last element of the cdr3 is the F in 'combining region'\n",
    "        # https://www.imgt.org/IMGTrepertoire/Proteins/alleles/index.php?species=Homo%20sapiens&group=TRBJ&gene=TRBJ-overview\n",
    "        \n",
    "        pattern = r'F G [A-Z] G'\n",
    "        j = f'{data[i, 6]}*0{int(data[i, 7])}'\n",
    "        seq_j = allele_dict[j]\n",
    "        match = re.search(pattern, seq_j)\n",
    "        Js[i] = seq_j[match.start()+1:] # F included in cdr3 \n",
    "    \n",
    "    return  Vs, Js\n",
    "\n",
    "@numba.jit(forceobj=True)\n",
    "def fetch_sequence_codes(data):\n",
    "    V_codes, J_codes = [None]*data.shape[0], [None]*data.shape[0]\n",
    "    for i in tqdm(range(data.shape[0]), position = 0, leave = True):\n",
    "        V_codes[i] = f'{data[i, 3]}*{int(data[i, 4])}'\n",
    "        J_codes[i] = f'{data[i, 6]}*{int(data[i, 7])}'\n",
    "        \n",
    "    return V_codes, J_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(list_of_samples):\n",
    "        result = {}\n",
    "        for sample in list_of_samples:\n",
    "            for k, v in sample.items():\n",
    "                if k not in result.keys():\n",
    "                    result[k] = [v]\n",
    "\n",
    "                else:\n",
    "                    result[k].append(v)\n",
    "                    \n",
    "        for k, v in result.items():\n",
    "            if k == 'v' or k == 'j' or k =='cdr3':\n",
    "                continue\n",
    "            result[k] = torch.stack(v)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 268032.34it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 4807.31it/s]\n"
     ]
    }
   ],
   "source": [
    "test_set = GeneratorDataset(test_data.iloc[:2000].to_numpy(), gene_cdr3, tokenizer, model.CDR3_max_length)\n",
    "test_loader = DataLoader(test_set, shuffle=False, batch_size=8, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/26 [00:00<?, ?it/s]/share/apps/anaconda-ci/fgci-centos7-anaconda/software/anaconda/2023-03/6a700484/lib/python3.10/site-packages/torch/nn/modules/transformer.py:296: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343995026/work/aten/src/ATen/NestedTensorImpl.cpp:177.)\n",
      "  output = torch._nested_tensor_from_mask(output, src_key_padding_mask.logical_not(), mask_check=False)\n",
      "100%|██████████| 26/26 [05:13<00:00, 12.05s/it]\n"
     ]
    }
   ],
   "source": [
    "for batch in test_loader:\n",
    "    cdr3_pred = multinomial_sample(model, batch['v'], batch['j'], batch['cdr3'], batch['pad_mask'], batch['length'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.,  6., 16.,  7., 15., 17., 24., 17., 11., 19., 22., 19., 19., 20.,\n",
       "        22., 20.])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdr3_pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S I G A E L K I H M F F Y'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(cdr3_pred[7].to(torch.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(torch\u001b[38;5;241m.\u001b[39mcat(prob, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mt(), cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviridis_r\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39myticks(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m30\u001b[39m), \u001b[43mnames\u001b[49m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxticks(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;28mint\u001b[39m(length[:,\u001b[38;5;241m1\u001b[39m])), \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m(length[:,\u001b[38;5;241m1\u001b[39m])))\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mcolorbar()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'names' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(torch.cat(prob, dim=0).t(), cmap='viridis_r')\n",
    "plt.yticks(range(0,30), names)\n",
    "plt.xticks(range(0,int(length[:,1])), range(0, int(length[:,1])))\n",
    "plt.colorbar()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (module anaconda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
