{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "import scipy.stats as stats\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer \n",
    "\n",
    "from process_data_new import process_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the .tsv file...\n",
      "Creating the allele codes...\n",
      "Loading the sequences...\n",
      "Masking the dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26427243/26427243 [04:34<00:00, 96415.74it/s] \n"
     ]
    }
   ],
   "source": [
    "# data_path = os.path.join(os.getcwd(), os.pardir, \"data\")\n",
    "# emerson_path =os.path.join(data_path, \"emerson\", \"emerson_processed\")\n",
    "# test_data = pd.read_csv(os.path.join(emerson_path, \"whole_seqs_nn_test.tsv\"), sep = '\\t')\n",
    "\n",
    "test_data = process_data(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_data, CDR3_data, J_data, tgt_data =test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A S S P D R D S P L H F'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CDR3_data[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Evaluation follows the steps of the evaluation utilized in TCRpeg model.\n",
    "\n",
    "https://github.com/jiangdada1221/TCRpeg/blob/main/tcrpeg/evaluate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26427243/26427243 [02:55<00:00, 150181.37it/s]\n"
     ]
    }
   ],
   "source": [
    "counts = {}\n",
    "for v, cdr, seq in tqdm(zip(V_data, CDR3_data,tgt_data), total = len(CDR3_data),leave = True, position = 0):\n",
    "\n",
    "    if  'C ' + cdr not in counts.keys():\n",
    "        counts['C ' +cdr] = [1,[seq], [(len(v)+1, len(cdr))]]\n",
    "    else:\n",
    "        counts['C ' +cdr][0] += 1\n",
    "        counts['C ' +cdr][1].append(seq)\n",
    "        counts['C ' +cdr][2].append((len(v)+1, len(cdr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_data_, seqs_, lengths_ = [], [], []\n",
    "\n",
    "for v in counts.values():\n",
    "    c_data_.append(v[0])\n",
    "    seqs_.append(v[1])\n",
    "    lengths_.append(v[2]) \n",
    "\n",
    "\n",
    "cdr3_seqs_ = list(counts.keys())\n",
    "c_data, cdr3_seqs, seqs, lengths = [], [], [], []\n",
    "\n",
    "for i in range(len(seqs_)):  #only need seqs that has appearance > 2 ??why?? --> No reason found for this but done since it is done in GRU paper\n",
    "    if c_data_[i] > 2:\n",
    "        c_data.append(c_data_[i])\n",
    "        cdr3_seqs.append(cdr3_seqs_[i])\n",
    "        seqs.append(seqs_[i])\n",
    "        lengths.append(lengths_[i])\n",
    "\n",
    "p_data = np.array(c_data)\n",
    "sum_p = np.sum(p_data)\n",
    "p_data = p_data / sum_p #normalized probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.35998147e-06, 3.96361952e-07, 2.47726220e-06, ...,\n",
       "       2.97271464e-07, 2.97271464e-07, 2.97271464e-07])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "checkpoint =  torch.load(\"../code/model_parallel_current/030823_customprotBERT_parallel_checkpoint.pth\",  map_location=\"cpu\")\n",
    "model = checkpoint[\"model\"]\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No batch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(model, src, length, cdr):\n",
    "    cdr_logits = model(src,\n",
    "                       length)\n",
    "    probabilities = cdr_logits.softmax(-1)\n",
    "    seq_prob = 1\n",
    "    \n",
    "    for i in range(cdr.shape[-1]):\n",
    "        seq_prob *= float(probabilities[:,i,int(cdr[:,i])])\n",
    "    return seq_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('Rostlab/prot_bert_bfd', add_special_tokens=False)\n",
    "torch.set_default_dtype(torch.float64)\n",
    "record = np.zeros(len(seqs))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, s in tqdm(enumerate(seqs), total= len(seqs), leave=True, position= 0):\n",
    "        s_prob = []\n",
    "        for j in range(len(counts[s][1])):\n",
    "            #print(f'seq {j+1} of {len(counts[s][1])} ')\n",
    "            src = tokenizer(counts[s][1][j], return_tensors = 'pt')['input_ids'][:, :-1] #remove [SEP]\n",
    "            length = torch.tensor(counts[s][2][j]).unsqueeze(0)\n",
    "            cdr = tokenizer(s[1:], return_tensors = 'pt')['input_ids'][:, 1:-1] #remove [CLS] and [SEP]\n",
    "            s_prob.append(sampling(model, src, length, cdr))\n",
    "        record[i] = sum(s_prob)/len(s_prob)\n",
    "        #print(record[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), os.pardir, \"code\", \"model_parallel_current\"))\n",
    "\n",
    "from CDR3Dataset import CDR3Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('Rostlab/prot_bert_bfd', add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v_test = \n",
    "cdr3_test = [ s[1:] for s, c in tqdm(zip(cdr3_seqs, c_data), total = len(cdr3_seqs), leave= True, position= 0) for _ in range(c)]\n",
    "\n",
    "lengths_test = []\n",
    "tgt_test = [] \n",
    "for s, l in tqdm(zip(seqs, lengths), total= len(seqs), leave= True, position= 0):\n",
    "    tgt_test += s\n",
    "    lengths_test += l\n",
    "\n",
    "v_test = []\n",
    "j_test = []\n",
    "for seq, lens in tqdm(zip(tgt_test, lengths_test), total = len(tgt_test), leave =True, position = 0):\n",
    "    v_test.append(seq[:lens[0]-1])\n",
    "    j_test.append(seq[lens[0]+lens[1]+1:]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cdr3_test[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_test[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CDR3Dataset(V = v_test, CDR3 = cdr3_test, J = j_test, tgt = tgt_test, tokenizer=tokenizer, evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset, shuffle=False, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(model, src, length, cdr, pad_mask):\n",
    "    #print(length)\n",
    "    cdr_logits = model(src,\n",
    "                       length,\n",
    "                       pad_mask)\n",
    "    # Continue here\n",
    "    probabilities = cdr_logits.log_softmax(-1)\n",
    "    \n",
    "    #think about batch of cdr3 sequences \n",
    "    target_onehot = torch.zeros(probabilities.shape)\n",
    "    \n",
    "    cdr = torch.nn.functional.pad(input=cdr, pad=(0, model.CDR3_max_length -cdr.shape[-1]))\n",
    "    \n",
    "    replace_tensor = torch.ones(probabilities.shape[0], model.CDR3_max_length, 30)\n",
    "    mask = torch.where(cdr>0, torch.tensor(1), cdr).unsqueeze(-1).expand(probabilities.shape)\n",
    "    \n",
    "    replace_tensor = replace_tensor*mask\n",
    "    #print(replace_tensor.shape)\n",
    "    #print(replace_tensor[0,:,:])\n",
    "    \n",
    "    #replace_tensor = torch.cat([torch.ones((probabilities.shape[0], int(length[0, 1]), 30)), torch.zeros((probabilities.shape[0], 26-int(length[0,1]),30))],dim =1)\n",
    "    '''\n",
    "    print(replace_tensor.shape)\n",
    "    print(target_onehot.shape)\n",
    "    print(cdr.view([src.shape[0], -1, 1])[0,:,:])\n",
    "    '''\n",
    "    # The repeat might not be needed if cdr is \"big\" tensor\n",
    "    target_onehot.scatter_(dim=2, index = cdr.view([src.shape[0], -1, 1]) ,src=replace_tensor)\n",
    "    seq_prob = target_onehot * probabilities\n",
    "    \n",
    "    #print(torch.exp(seq_prob[0,:,:].sum(-1).sum(-1)))\n",
    "    \n",
    "    seq_prob = torch.exp(seq_prob.sum(-1).sum(-1))\n",
    "    print(seq_prob)\n",
    "    \n",
    "    return seq_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "max_length = 0\n",
    "for s in seqs:\n",
    "    for i in range(len(counts[s][1])):\n",
    "        max_length = max(max_length, len(counts[s][1][i].split())+3)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "seq_probs = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        #if i > 0: break \n",
    "        batch = {k:v.to(device) for k,v in batch.items()}\n",
    "        \n",
    "        probs = sampling(model = model,\n",
    "                             src = batch['seq'],\n",
    "                             length = batch['length'],\n",
    "                             cdr = batch['CDR3_label'],\n",
    "                             pad_mask = batch['pad_mask'])\n",
    "        seq_probs.append(probs)\n",
    "seq_probs = torch.cat(seq_probs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr3_probs ={}\n",
    "for i, cdr in enumerate(cdr3_test):\n",
    "    if i > 63 : break \n",
    "    if cdr not in cdr3_probs.keys():\n",
    "        cdr3_probs[cdr] = [float(seq_probs[i])]\n",
    "    else:\n",
    "        cdr3_probs[cdr].append(float(seq_probs[i]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr3_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in cdr3_probs.items():\n",
    "    cdr3_probs[k] = sum(v)/len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr3_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the P_infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../code/P_infer_CDR3_seqs.pkl', 'rb') as f:\n",
    "    cdr3_probs = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = np.array(list(cdr3_probs.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient are : 0.0365\n"
     ]
    }
   ],
   "source": [
    "record_sum = np.sum(record)\n",
    "record = record/record_sum\n",
    "# kl = kl_divergence(p_data,record)\n",
    "corr = stats.pearsonr(p_data,record)[0]\n",
    "print('Pearson correlation coefficient are : {}'.format(str(round(corr,4))))\n",
    "#return corr,p_data,record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C A S S P D R D S P L H F',\n",
       " 'C A S S R S T G Q G Y T F',\n",
       " 'C A S S F R A D T E A F F',\n",
       " 'C A S S L A Y E Q Y F',\n",
       " 'C A S S F T G D T E A F F']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdr3_seqs[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (module anaconda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
